================================================================
Repository Structure
================================================================
.gitignore
aaa.py
README_EN.md
README.md
requirements.txt
setup.py
src/markdown_hierarchy_splitter/__init__.py
src/markdown_hierarchy_splitter/config.py
src/markdown_hierarchy_splitter/processor.py

================================================================
Repository Files
================================================================

================
File: .gitignore
================
# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg

# Virtual Environment
venv/
ENV/
env/
.env
.venv

# IDE
.idea/
.vscode/
*.swp
*.swo

# OS
.DS_Store
Thumbs.db

================
File: aaa.py
================
# -*- coding: utf-8 -*-
from markdown_hierarchy_splitter import MarkdownProcessorLocal

# åˆå§‹åŒ–å¤„ç†å™¨
processor = MarkdownProcessorLocal(chunk_size=300)

# å¤„ç†Markdownæ–‡ä»¶
with open('./data/input/20241116-æ­£æ–‡.md', 'r', encoding='utf-8') as f:
    markdown_text = f.read()

# è·å–ä¿ç•™å±‚çº§ç»“æ„çš„æ–‡æœ¬å—
chunks = list(processor.process_markdown(markdown_text))

================
File: README.md
================
# markdown-hierarchy-splitter

[![PyPI version](https://badge.fury.io/py/markdown-hierarchy-splitter.svg)](https://badge.fury.io/py/markdown-hierarchy-splitter)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

ä¸€ä¸ªä¸ºRAGç³»ç»Ÿè®¾è®¡çš„Markdownæ–‡æ¡£åˆ†å‰²å·¥å…·ï¼Œå®Œæ•´ä¿ç•™æ–‡æ¡£å±‚çº§ç»“æ„ï¼Œè§£å†³ä¼ ç»Ÿåˆ‡åˆ†å™¨ä¸¢å¤±æ ‡é¢˜å±‚çº§ä¸ç ´åè¡¨æ ¼å®Œæ•´æ€§çš„é—®é¢˜ã€‚

## ğŸŒŸ ä¸»è¦ç‰¹æ€§

- **å®Œæ•´ä¿ç•™æ–‡æ¡£å±‚çº§**: æ¯ä¸ªåˆ‡åˆ†ç‰‡æ®µéƒ½ä¿ç•™å®Œæ•´çš„æ ‡é¢˜è·¯å¾„(ä¸€çº§æ ‡é¢˜ > äºŒçº§æ ‡é¢˜ > ä¸‰çº§æ ‡é¢˜...)
- **æ™ºèƒ½è¡¨æ ¼å¤„ç†**: ä¿æŒè¡¨æ ¼å®Œæ•´æ€§ï¼ŒåŒæ—¶éµå¾ªå—å¤§å°é™åˆ¶
- **å¤šæ ¼å¼å¯¼å‡º**: æ”¯æŒå¯¼å‡ºä¸ºMarkdownã€Word(.docx)å’ŒCSVæ ¼å¼
- **çµæ´»é…ç½®**: å¯è°ƒæ•´çš„åˆ†å—å¤§å°ï¼Œæ™ºèƒ½è¾¹ç•Œæ£€æµ‹
- **è½»é‡çº§ä¾èµ–**: ä¸»è¦ä½¿ç”¨Pythonæ ‡å‡†åº“ï¼Œæœ€å°åŒ–å¤–éƒ¨ä¾èµ–

## ğŸ¯ è§£å†³çš„é—®é¢˜

ä¼ ç»ŸRAGç³»ç»Ÿåœ¨å¤„ç†æ–‡æ¡£æ—¶é€šå¸¸é¢ä¸´ä¸¤ä¸ªå…³é”®é—®é¢˜ï¼š

1. **ä¸¢å¤±æ–‡æ¡£ç»“æ„**: æ–‡æ¡£è¢«åˆ†å‰²æˆå—åï¼Œå¾€å¾€ä¸¢å¤±äº†ç« èŠ‚å±‚çº§å…³ç³»
2. **è¡¨æ ¼ç ´ç¢**: è¡¨æ ¼å¸¸å¸¸è¢«ä»ä¸­é—´åˆ‡æ–­ï¼Œå¯¼è‡´å†…å®¹éš¾ä»¥ç†è§£

æœ¬å·¥å…·é€šè¿‡ä»¥ä¸‹æ–¹å¼è§£å†³è¿™äº›é—®é¢˜ï¼š
- ä¸ºæ¯ä¸ªæ–‡æœ¬å—ä¿ç•™å®Œæ•´çš„æ ‡é¢˜è·¯å¾„
- å°†è¡¨æ ¼ä½œä¸ºåŸå­å•ä½å¤„ç†ï¼Œç¡®ä¿å…¶å®Œæ•´æ€§

## ğŸš€ å®‰è£…æ–¹æ³•

### ä»PyPIå®‰è£…ï¼ˆæ¨èï¼‰
```bash
pip install markdown-hierarchy-splitter
```

### æœ¬åœ°å¼€å‘å®‰è£…
1. å…‹éš†ä»“åº“
```bash
git clone https://github.com/yourusername/markdown-hierarchy-splitter.git
cd markdown-hierarchy-splitter
```

2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆå¯é€‰ä½†æ¨èï¼‰
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# æˆ–
.\venv\Scripts\activate  # Windows
```

3. å®‰è£…å¼€å‘æ¨¡å¼
```bash
pip install -e .
```
4. å¦‚æœå®‰è£…é‡åˆ°é—®é¢˜ï¼Œæ‚¨ä¹Ÿå¯ä»¥å°è¯•ä½¿ç”¨è¾ƒä½ç‰ˆæœ¬çš„setuptoolsï¼š
```bash
bashCopypip install setuptools==58.2.0
pip install -e .
```

```

## ğŸ“š ä½¿ç”¨æ–¹æ³•
### å‰æ
éœ€è¦markdownå±‚çº§æ˜æ˜¾æ ‡æ³¨ï¼Œè‹¥æ²¡æœ‰ä¸€çº§äºŒçº§ä¸‰çº§æ ‡é¢˜ï¼ˆ#ï¼Œ##ï¼Œ###ï¼Œ...ï¼‰ï¼Œåˆ™æ— æ³•æå–ã€‚

### åŸºæœ¬ç”¨æ³•
```python
from markdown_hierarchy_splitter import MarkdownProcessorLocal

# åˆå§‹åŒ–å¤„ç†å™¨
processor = MarkdownProcessorLocal(chunk_size=300)

# å¤„ç†Markdownæ–‡ä»¶
with open('data/input/example.md', 'r', encoding='utf-8') as f:
    markdown_text = f.read()

# è·å–ä¿ç•™å±‚çº§ç»“æ„çš„æ–‡æœ¬å—
chunks = list(processor.process_markdown(markdown_text))
```

### å¯¼å‡ºä¸ºå¤šç§æ ¼å¼
```python
from markdown_hierarchy_splitter import create_output_files

# æ–‡ä»¶ä¼šè‡ªåŠ¨ä» data/input è¯»å–ï¼Œå¹¶ä¿å­˜åˆ° data/output
results = create_output_files(
    input_file="example.md",  # åªéœ€æä¾›æ–‡ä»¶å
    chunk_size=300
)
```

### é¡¹ç›®ç»“æ„è¯´æ˜
```
markdown-structure-splitter/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ input/    # å­˜æ”¾å¾…å¤„ç†çš„Markdownæ–‡ä»¶
â”‚   â””â”€â”€ output/   # å­˜æ”¾å¤„ç†åçš„è¾“å‡ºæ–‡ä»¶
â””â”€â”€ src/
    â””â”€â”€ markdown_hierarchy_splitter/
        â”œâ”€â”€ processor.py  # æ ¸å¿ƒå¤„ç†é€»è¾‘
        â””â”€â”€ config.py     # é…ç½®æ–‡ä»¶
```

## ğŸ“‹ ç¯å¢ƒè¦æ±‚

- Python 3.6+
- python-docx
- langchain-text-splitters

## ğŸˆ ä½¿ç”¨å°è´´å£«

1. **è¾“å…¥æ–‡ä»¶æ”¾ç½®**ï¼š
   - å°†éœ€è¦å¤„ç†çš„Markdownæ–‡ä»¶æ”¾åœ¨ `data/input` ç›®å½•ä¸‹
   - å¤„ç†åçš„æ–‡ä»¶ä¼šè‡ªåŠ¨ä¿å­˜åœ¨ `data/output` ç›®å½•ä¸‹å¯¹åº”çš„å­æ–‡ä»¶å¤¹ä¸­

2. **å‚æ•°è°ƒä¼˜**ï¼š
   - å»ºè®®å°†chunk_sizeè®¾ç½®åœ¨300-500ä¹‹é—´
   - å¯¹äºåŒ…å«å¤§é‡è¡¨æ ¼çš„æ–‡æ¡£ï¼Œå¯ä»¥é€‚å½“å¢åŠ chunk_size
   - å¯¼å‡ºWordæ ¼å¼æ—¶ä¼šè‡ªåŠ¨åº”ç”¨ä¸€äº›åŸºç¡€æ ¼å¼è®¾ç½®

3. **æ€§èƒ½å»ºè®®**ï¼š
   - å¯¹äºå¤§æ–‡ä»¶å¤„ç†ï¼Œå»ºè®®å…ˆæµ‹è¯•å°éƒ¨åˆ†å†…å®¹
   - ç¡®ä¿ç³»ç»Ÿæœ‰è¶³å¤Ÿçš„å†…å­˜å¤„ç†å¤§å‹æ–‡æ¡£

================
File: requirements.txt
================
langchain
python-docx

================
File: setup.py
================
# -*- coding: utf-8 -*-
from setuptools import setup, find_packages

try:
    with open("README.md", "r", encoding="utf-8") as fh:
        long_description = fh.read()
except:
    long_description = "A tool for splitting markdown files while preserving structure"

setup(
    name="markdown-hierarchy-splitter",
    # ä½¿ç”¨æ ‡å‡†ç‰ˆæœ¬æ ¼å¼
    version="0.1.0.dev0",
    packages=find_packages(where="src"),
    package_dir={"": "src"},
    install_requires=[
        "python-docx>=0.8.10",
        "langchain-text-splitters>=0.0.1",
        "setuptools>=61.0.0"  # æ·»åŠ setuptoolsæœ€ä½ç‰ˆæœ¬è¦æ±‚
    ],
    python_requires=">=3.10",
    author="Han Wenbo",
    author_email="",
    description="A tool for splitting markdown files while preserving structure",
    long_description=long_description,
    long_description_content_type="text/markdown",
    url="https://github.com/hwb96/markdown-structure-splitter",
    classifiers=[
        "Development Status :: 3 - Alpha",
        "Programming Language :: Python :: 3",
        "Programming Language :: Python :: 3.10",
        "License :: OSI Approved :: MIT License",
        "Operating System :: OS Independent",
    ],
)

================
File: src/markdown_hierarchy_splitter/__init__.py
================
from .processor import MarkdownProcessorLocal

================
File: src/markdown_hierarchy_splitter/config.py
================
# -*- coding: utf-8 -*-
import os
from pathlib import Path

# è·å–é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = Path(__file__).parent.parent.parent

# æ•°æ®ç›®å½•é…ç½®
DATA_DIR = PROJECT_ROOT / 'data'
INPUT_DIR = DATA_DIR / 'input'
OUTPUT_DIR = DATA_DIR / 'output'

# ç¡®ä¿ç›®å½•å­˜åœ¨
DATA_DIR.mkdir(exist_ok=True)
INPUT_DIR.mkdir(exist_ok=True)
OUTPUT_DIR.mkdir(exist_ok=True)

================
File: src/markdown_hierarchy_splitter/processor.py
================
from typing import List, Dict, Tuple
import os
from pathlib import Path
from docx import Document
from docx.shared import Pt
import csv
from langchain_text_splitters import RecursiveCharacterTextSplitter
from .config import INPUT_DIR, OUTPUT_DIR


class MarkdownProcessorLocal:
    def __init__(self, chunk_size: int = 300):
        self.chunk_size = chunk_size
        self.current_headers = {1: "", 2: "", 3: "", 4: "", 5: "", 6: ""}
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=chunk_size,
            chunk_overlap=0,
            separators=["\n\n", "\n", "ã€‚", "ï¼›", "ï¼Œ", " ", ""]
        )

    def get_header_level(self, line: str) -> int:
        if not line.strip().startswith('#'):
            return 0
        level = 0
        for char in line.strip():
            if char == '#':
                level += 1
            else:
                break
        return level

    def update_headers(self, line: str, level: int):
        header_text = line.lstrip('#').strip()
        self.current_headers[level] = header_text
        for i in range(level + 1, 7):
            self.current_headers[i] = ""

    def collect_current_headers(self) -> str:
        headers = []
        for level in range(1, 7):
            if self.current_headers[level]:
                headers.append("#" * level + " " + self.current_headers[level])
        return "\n".join(headers) + "\n\n" if headers else ""

    def is_table_separator(self, line: str) -> bool:
        return bool(line.strip().startswith('|') and '----' in line)

    def is_table_row(self, line: str) -> bool:
        return bool(line.strip().startswith('|') and line.strip().endswith('|'))

    def split_table_row(self, row: str) -> List[str]:
        return [cell.strip() for cell in row.strip('|').split('|')]

    def join_table_row(self, cells: List[str]) -> str:
        return '| ' + ' | '.join(cells) + ' |'

    def get_first_column(self, row: str) -> str:
        cells = self.split_table_row(row)
        return cells[0] if cells else ""

    def split_table(self, table_lines: List[str]) -> List[List[str]]:
        if len(table_lines) < 3:
            return [table_lines]

        header_row = table_lines[0]
        separator_row = table_lines[1]
        content_rows = table_lines[2:]

        if len('\n'.join(table_lines)) <= self.chunk_size:
            return [table_lines]

        rows_per_chunk = max(2, (self.chunk_size - len(header_row) - len(separator_row)) //
                             (len(content_rows[0]) if content_rows else 1))

        split_tables = []
        for i in range(0, len(content_rows), rows_per_chunk):
            chunk_rows = content_rows[i:i + rows_per_chunk]
            split_tables.append([
                header_row,
                separator_row,
                *chunk_rows
            ])

        return split_tables

    def extract_table(self, lines: List[str], start_idx: int) -> Tuple[List[str], int]:
        table_lines = []
        i = start_idx

        while i >= 0 and (self.is_table_row(lines[i]) or self.is_table_separator(lines[i])):
            table_lines.insert(0, lines[i])
            i -= 1

        i = start_idx + 1
        while i < len(lines) and (self.is_table_row(lines[i]) or self.is_table_separator(lines[i])):
            table_lines.append(lines[i])
            i += 1

        return table_lines, i - 1

    def process_markdown(self, markdown_text: str):
        lines = markdown_text.split('\n')
        content_buffer = []
        headers = ""
        i = 0

        while i < len(lines):
            line = lines[i].rstrip()

            if not line:
                content_buffer.append(line)
                i += 1
                continue

            level = self.get_header_level(line)
            if level > 0:
                if content_buffer:
                    text = "\n".join(content_buffer)
                    if text.strip():
                        chunks = self.text_splitter.split_text(text.strip())
                        for chunk in chunks:
                            yield headers + chunk + "\n"
                    content_buffer = []

                self.update_headers(line, level)
                headers = self.collect_current_headers()
            elif self.is_table_separator(line) or self.is_table_row(line):
                table_lines, end_idx = self.extract_table(lines, i)

                if content_buffer:
                    text = "\n".join(content_buffer)
                    if text.strip():
                        chunks = self.text_splitter.split_text(text.strip())
                        for chunk in chunks:
                            yield headers + chunk + "\n"
                    content_buffer = []

                split_tables = self.split_table(table_lines)
                for table in split_tables:
                    yield headers + "\n".join(table) + "\n\n"

                i = end_idx + 1
                continue
            else:
                content_buffer.append(line)

            i += 1

        if content_buffer:
            text = "\n".join(content_buffer)
            if text.strip():
                chunks = self.text_splitter.split_text(text.strip())
                for chunk in chunks:
                    yield headers + chunk + "\n"


def create_output_files(input_file: str, chunk_size: int = 300):
    """å¤„ç†Markdownæ–‡ä»¶å¹¶ä¿å­˜ä¸ºå¤šç§æ ¼å¼

    Args:
        input_file: è¾“å…¥æ–‡ä»¶åï¼ˆä¸æ˜¯å®Œæ•´è·¯å¾„ï¼‰
        chunk_size: åˆ†å—å¤§å°
    """
    try:
        # æ„å»ºå®Œæ•´çš„è¾“å…¥æ–‡ä»¶è·¯å¾„
        input_path = INPUT_DIR / input_file
        base_name = input_path.stem

        # åœ¨outputç›®å½•ä¸‹åˆ›å»ºå­ç›®å½•
        output_subdir = OUTPUT_DIR / base_name
        output_subdir.mkdir(exist_ok=True)

        # å®šä¹‰è¾“å‡ºæ–‡ä»¶è·¯å¾„
        md_output = output_subdir / f"{base_name}.md"
        docx_output = output_subdir / f"{base_name}.docx"
        csv_output = output_subdir / f"{base_name}.csv"

        # è¯»å–è¾“å…¥æ–‡ä»¶
        with open(input_path, 'r', encoding='utf-8') as f:
            markdown_text = f.read()

        # å¤„ç†æ–‡æœ¬
        processor = MarkdownProcessorLocal(chunk_size=chunk_size)
        results = list(processor.process_markdown(markdown_text))

        # å®šä¹‰åˆ†éš”ç¬¦
        separator = "=" * 40  # å¯ä»¥è‡ªå®šä¹‰åˆ†éš”ç¬¦

        # 1. ä¿å­˜ Markdown æ–‡ä»¶
        with open(md_output, 'w', encoding='utf-8') as f:
            for i, chunk in enumerate(results, 1):
                f.write(f"\n{separator}\n\n")
                f.write(chunk)

        # 2. åˆ›å»º Word æ–‡æ¡£
        doc = Document()
        for i, chunk in enumerate(results, 1):
            # æ·»åŠ åˆ†éš”ç¬¦
            separator_paragraph = doc.add_paragraph()
            separator_paragraph.add_run('=' * 40)

            # æ·»åŠ å†…å®¹
            content_paragraph = doc.add_paragraph()
            content_paragraph.add_run(chunk)

            # è®¾ç½®å­—ä½“
            for run in separator_paragraph.runs + content_paragraph.runs:
                run.font.size = Pt(11)
                run.font.name = 'Arial'

        doc.save(docx_output)

        # 3. ä¿å­˜ CSV æ–‡ä»¶
        with open(csv_output, 'w', encoding='utf-8', newline='') as f:
            writer = csv.writer(f)
            writer.writerow(['Content'])  # å†™å…¥è¡¨å¤´
            for chunk in results:
                writer.writerow([chunk.strip()])

        print(f"å¤„ç†å®Œæˆï¼å…±ç”Ÿæˆ {len(results)} ä¸ªæ–‡æœ¬å—")
        print(f"è¾“å‡ºæ–‡ä»¶å·²ä¿å­˜è‡³ {output_subdir} ç›®å½•ï¼š")
        print(f"- Markdownæ–‡ä»¶ï¼š{md_output}")
        print(f"- Wordæ–‡ä»¶ï¼š{docx_output}")
        print(f"- CSVæ–‡ä»¶ï¼š{csv_output}")

        return results

    except FileNotFoundError:
        print(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°è¾“å…¥æ–‡ä»¶ {input_path}")
    except Exception as e:
        print(f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼š{str(e)}")


if __name__ == "__main__":
    results = create_output_files(
        input_file="./20241116-æ­£æ–‡.md",
        chunk_size=300
    )
