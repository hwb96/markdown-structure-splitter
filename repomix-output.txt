================================================================
Repository Structure
================================================================
.gitignore
aaa.py
README_EN.md
README.md
requirements.txt
setup.py
src/markdown_hierarchy_splitter/__init__.py
src/markdown_hierarchy_splitter/config.py
src/markdown_hierarchy_splitter/processor.py

================================================================
Repository Files
================================================================

================
File: .gitignore
================
# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg

# Virtual Environment
venv/
ENV/
env/
.env
.venv

# IDE
.idea/
.vscode/
*.swp
*.swo

# OS
.DS_Store
Thumbs.db

================
File: aaa.py
================
# -*- coding: utf-8 -*-
from markdown_hierarchy_splitter import MarkdownProcessorLocal

# 初始化处理器
processor = MarkdownProcessorLocal(chunk_size=300)

# 处理Markdown文件
with open('./data/input/20241116-正文.md', 'r', encoding='utf-8') as f:
    markdown_text = f.read()

# 获取保留层级结构的文本块
chunks = list(processor.process_markdown(markdown_text))

================
File: README.md
================
# markdown-hierarchy-splitter

[![PyPI version](https://badge.fury.io/py/markdown-hierarchy-splitter.svg)](https://badge.fury.io/py/markdown-hierarchy-splitter)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

一个为RAG系统设计的Markdown文档分割工具，完整保留文档层级结构，解决传统切分器丢失标题层级与破坏表格完整性的问题。

## 🌟 主要特性

- **完整保留文档层级**: 每个切分片段都保留完整的标题路径(一级标题 > 二级标题 > 三级标题...)
- **智能表格处理**: 保持表格完整性，同时遵循块大小限制
- **多格式导出**: 支持导出为Markdown、Word(.docx)和CSV格式
- **灵活配置**: 可调整的分块大小，智能边界检测
- **轻量级依赖**: 主要使用Python标准库，最小化外部依赖

## 🎯 解决的问题

传统RAG系统在处理文档时通常面临两个关键问题：

1. **丢失文档结构**: 文档被分割成块后，往往丢失了章节层级关系
2. **表格破碎**: 表格常常被从中间切断，导致内容难以理解

本工具通过以下方式解决这些问题：
- 为每个文本块保留完整的标题路径
- 将表格作为原子单位处理，确保其完整性

## 🚀 安装方法

### 从PyPI安装（推荐）
```bash
pip install markdown-hierarchy-splitter
```

### 本地开发安装
1. 克隆仓库
```bash
git clone https://github.com/yourusername/markdown-hierarchy-splitter.git
cd markdown-hierarchy-splitter
```

2. 创建虚拟环境（可选但推荐）
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# 或
.\venv\Scripts\activate  # Windows
```

3. 安装开发模式
```bash
pip install -e .
```
4. 如果安装遇到问题，您也可以尝试使用较低版本的setuptools：
```bash
bashCopypip install setuptools==58.2.0
pip install -e .
```

```

## 📚 使用方法
### 前提
需要markdown层级明显标注，若没有一级二级三级标题（#，##，###，...），则无法提取。

### 基本用法
```python
from markdown_hierarchy_splitter import MarkdownProcessorLocal

# 初始化处理器
processor = MarkdownProcessorLocal(chunk_size=300)

# 处理Markdown文件
with open('data/input/example.md', 'r', encoding='utf-8') as f:
    markdown_text = f.read()

# 获取保留层级结构的文本块
chunks = list(processor.process_markdown(markdown_text))
```

### 导出为多种格式
```python
from markdown_hierarchy_splitter import create_output_files

# 文件会自动从 data/input 读取，并保存到 data/output
results = create_output_files(
    input_file="example.md",  # 只需提供文件名
    chunk_size=300
)
```

### 项目结构说明
```
markdown-structure-splitter/
├── data/
│   ├── input/    # 存放待处理的Markdown文件
│   └── output/   # 存放处理后的输出文件
└── src/
    └── markdown_hierarchy_splitter/
        ├── processor.py  # 核心处理逻辑
        └── config.py     # 配置文件
```

## 📋 环境要求

- Python 3.6+
- python-docx
- langchain-text-splitters

## 🎈 使用小贴士

1. **输入文件放置**：
   - 将需要处理的Markdown文件放在 `data/input` 目录下
   - 处理后的文件会自动保存在 `data/output` 目录下对应的子文件夹中

2. **参数调优**：
   - 建议将chunk_size设置在300-500之间
   - 对于包含大量表格的文档，可以适当增加chunk_size
   - 导出Word格式时会自动应用一些基础格式设置

3. **性能建议**：
   - 对于大文件处理，建议先测试小部分内容
   - 确保系统有足够的内存处理大型文档

================
File: requirements.txt
================
langchain
python-docx

================
File: setup.py
================
# -*- coding: utf-8 -*-
from setuptools import setup, find_packages

try:
    with open("README.md", "r", encoding="utf-8") as fh:
        long_description = fh.read()
except:
    long_description = "A tool for splitting markdown files while preserving structure"

setup(
    name="markdown-hierarchy-splitter",
    # 使用标准版本格式
    version="0.1.0.dev0",
    packages=find_packages(where="src"),
    package_dir={"": "src"},
    install_requires=[
        "python-docx>=0.8.10",
        "langchain-text-splitters>=0.0.1",
        "setuptools>=61.0.0"  # 添加setuptools最低版本要求
    ],
    python_requires=">=3.10",
    author="Han Wenbo",
    author_email="",
    description="A tool for splitting markdown files while preserving structure",
    long_description=long_description,
    long_description_content_type="text/markdown",
    url="https://github.com/hwb96/markdown-structure-splitter",
    classifiers=[
        "Development Status :: 3 - Alpha",
        "Programming Language :: Python :: 3",
        "Programming Language :: Python :: 3.10",
        "License :: OSI Approved :: MIT License",
        "Operating System :: OS Independent",
    ],
)

================
File: src/markdown_hierarchy_splitter/__init__.py
================
from .processor import MarkdownProcessorLocal

================
File: src/markdown_hierarchy_splitter/config.py
================
# -*- coding: utf-8 -*-
import os
from pathlib import Path

# 获取项目根目录
PROJECT_ROOT = Path(__file__).parent.parent.parent

# 数据目录配置
DATA_DIR = PROJECT_ROOT / 'data'
INPUT_DIR = DATA_DIR / 'input'
OUTPUT_DIR = DATA_DIR / 'output'

# 确保目录存在
DATA_DIR.mkdir(exist_ok=True)
INPUT_DIR.mkdir(exist_ok=True)
OUTPUT_DIR.mkdir(exist_ok=True)

================
File: src/markdown_hierarchy_splitter/processor.py
================
from typing import List, Dict, Tuple
import os
from pathlib import Path
from docx import Document
from docx.shared import Pt
import csv
from langchain_text_splitters import RecursiveCharacterTextSplitter
from .config import INPUT_DIR, OUTPUT_DIR


class MarkdownProcessorLocal:
    def __init__(self, chunk_size: int = 300):
        self.chunk_size = chunk_size
        self.current_headers = {1: "", 2: "", 3: "", 4: "", 5: "", 6: ""}
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=chunk_size,
            chunk_overlap=0,
            separators=["\n\n", "\n", "。", "；", "，", " ", ""]
        )

    def get_header_level(self, line: str) -> int:
        if not line.strip().startswith('#'):
            return 0
        level = 0
        for char in line.strip():
            if char == '#':
                level += 1
            else:
                break
        return level

    def update_headers(self, line: str, level: int):
        header_text = line.lstrip('#').strip()
        self.current_headers[level] = header_text
        for i in range(level + 1, 7):
            self.current_headers[i] = ""

    def collect_current_headers(self) -> str:
        headers = []
        for level in range(1, 7):
            if self.current_headers[level]:
                headers.append("#" * level + " " + self.current_headers[level])
        return "\n".join(headers) + "\n\n" if headers else ""

    def is_table_separator(self, line: str) -> bool:
        return bool(line.strip().startswith('|') and '----' in line)

    def is_table_row(self, line: str) -> bool:
        return bool(line.strip().startswith('|') and line.strip().endswith('|'))

    def split_table_row(self, row: str) -> List[str]:
        return [cell.strip() for cell in row.strip('|').split('|')]

    def join_table_row(self, cells: List[str]) -> str:
        return '| ' + ' | '.join(cells) + ' |'

    def get_first_column(self, row: str) -> str:
        cells = self.split_table_row(row)
        return cells[0] if cells else ""

    def split_table(self, table_lines: List[str]) -> List[List[str]]:
        if len(table_lines) < 3:
            return [table_lines]

        header_row = table_lines[0]
        separator_row = table_lines[1]
        content_rows = table_lines[2:]

        if len('\n'.join(table_lines)) <= self.chunk_size:
            return [table_lines]

        rows_per_chunk = max(2, (self.chunk_size - len(header_row) - len(separator_row)) //
                             (len(content_rows[0]) if content_rows else 1))

        split_tables = []
        for i in range(0, len(content_rows), rows_per_chunk):
            chunk_rows = content_rows[i:i + rows_per_chunk]
            split_tables.append([
                header_row,
                separator_row,
                *chunk_rows
            ])

        return split_tables

    def extract_table(self, lines: List[str], start_idx: int) -> Tuple[List[str], int]:
        table_lines = []
        i = start_idx

        while i >= 0 and (self.is_table_row(lines[i]) or self.is_table_separator(lines[i])):
            table_lines.insert(0, lines[i])
            i -= 1

        i = start_idx + 1
        while i < len(lines) and (self.is_table_row(lines[i]) or self.is_table_separator(lines[i])):
            table_lines.append(lines[i])
            i += 1

        return table_lines, i - 1

    def process_markdown(self, markdown_text: str):
        lines = markdown_text.split('\n')
        content_buffer = []
        headers = ""
        i = 0

        while i < len(lines):
            line = lines[i].rstrip()

            if not line:
                content_buffer.append(line)
                i += 1
                continue

            level = self.get_header_level(line)
            if level > 0:
                if content_buffer:
                    text = "\n".join(content_buffer)
                    if text.strip():
                        chunks = self.text_splitter.split_text(text.strip())
                        for chunk in chunks:
                            yield headers + chunk + "\n"
                    content_buffer = []

                self.update_headers(line, level)
                headers = self.collect_current_headers()
            elif self.is_table_separator(line) or self.is_table_row(line):
                table_lines, end_idx = self.extract_table(lines, i)

                if content_buffer:
                    text = "\n".join(content_buffer)
                    if text.strip():
                        chunks = self.text_splitter.split_text(text.strip())
                        for chunk in chunks:
                            yield headers + chunk + "\n"
                    content_buffer = []

                split_tables = self.split_table(table_lines)
                for table in split_tables:
                    yield headers + "\n".join(table) + "\n\n"

                i = end_idx + 1
                continue
            else:
                content_buffer.append(line)

            i += 1

        if content_buffer:
            text = "\n".join(content_buffer)
            if text.strip():
                chunks = self.text_splitter.split_text(text.strip())
                for chunk in chunks:
                    yield headers + chunk + "\n"


def create_output_files(input_file: str, chunk_size: int = 300):
    """处理Markdown文件并保存为多种格式

    Args:
        input_file: 输入文件名（不是完整路径）
        chunk_size: 分块大小
    """
    try:
        # 构建完整的输入文件路径
        input_path = INPUT_DIR / input_file
        base_name = input_path.stem

        # 在output目录下创建子目录
        output_subdir = OUTPUT_DIR / base_name
        output_subdir.mkdir(exist_ok=True)

        # 定义输出文件路径
        md_output = output_subdir / f"{base_name}.md"
        docx_output = output_subdir / f"{base_name}.docx"
        csv_output = output_subdir / f"{base_name}.csv"

        # 读取输入文件
        with open(input_path, 'r', encoding='utf-8') as f:
            markdown_text = f.read()

        # 处理文本
        processor = MarkdownProcessorLocal(chunk_size=chunk_size)
        results = list(processor.process_markdown(markdown_text))

        # 定义分隔符
        separator = "=" * 40  # 可以自定义分隔符

        # 1. 保存 Markdown 文件
        with open(md_output, 'w', encoding='utf-8') as f:
            for i, chunk in enumerate(results, 1):
                f.write(f"\n{separator}\n\n")
                f.write(chunk)

        # 2. 创建 Word 文档
        doc = Document()
        for i, chunk in enumerate(results, 1):
            # 添加分隔符
            separator_paragraph = doc.add_paragraph()
            separator_paragraph.add_run('=' * 40)

            # 添加内容
            content_paragraph = doc.add_paragraph()
            content_paragraph.add_run(chunk)

            # 设置字体
            for run in separator_paragraph.runs + content_paragraph.runs:
                run.font.size = Pt(11)
                run.font.name = 'Arial'

        doc.save(docx_output)

        # 3. 保存 CSV 文件
        with open(csv_output, 'w', encoding='utf-8', newline='') as f:
            writer = csv.writer(f)
            writer.writerow(['Content'])  # 写入表头
            for chunk in results:
                writer.writerow([chunk.strip()])

        print(f"处理完成！共生成 {len(results)} 个文本块")
        print(f"输出文件已保存至 {output_subdir} 目录：")
        print(f"- Markdown文件：{md_output}")
        print(f"- Word文件：{docx_output}")
        print(f"- CSV文件：{csv_output}")

        return results

    except FileNotFoundError:
        print(f"错误：找不到输入文件 {input_path}")
    except Exception as e:
        print(f"处理过程中发生错误：{str(e)}")


if __name__ == "__main__":
    results = create_output_files(
        input_file="./20241116-正文.md",
        chunk_size=300
    )
